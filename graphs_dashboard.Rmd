---
title: "What We Talk About When We Talk About Data Science on Medium.com"
output: 
  flexdashboard::flex_dashboard:
    source_code: embed
    theme: journal
runtime: shiny

---

```{r setup, include=FALSE}
## Import libraries
library(flexdashboard)
library(shinyWidgets)
library(plyr)
library(dplyr)
library(igraph)
library(ggraph)

## Set seed for ggraph package
set.seed(1)
```



  

Explore top article title keywords
=========================================


Column {.sidebar}
-----------------------------------------------------------------------

<hr>

Use the controls below to explore how popular topics in data science have changed over the years:

<br> 

```{r}
sliderInput("year", HTML("<b>Select the year of publication:</b>"), 
            min = 2012, max = 2019, value = 2019,
            sep="", animate=animationOptions(interval = 4000, loop = FALSE, playButton = NULL,
  pauseButton = NULL))
```

<br>

<center>
```{r}
knobInput(
  "knob",
  HTML("<b>Select the number of bigrams to visualize:</b>"),
  35,
  min = 10, max = 60,
  step = 5, angleOffset = 30, angleArc = 300,
  cursor = TRUE,
  thickness = NULL,
  lineCap = "round",
  displayInput = TRUE,
  displayPrevious = FALSE,
  rotation = "anticlockwise",
  fgColor = NULL,
  inputColor = NULL,
  bgColor = NULL,
  readOnly = FALSE,
  skin = NULL,
  width = NULL,
  height = NULL,
  immediate = FALSE
)
```
</center>

<br><hr><br>

Please see [here](http://rpubs.com/nchelaru/medium_ds_nlp) for a detailed run-down of the workflow for web scraping and data preparation, and the [Github repo](https://github.com/nchelaru/medium_scrapy) for raw and processed data used in this analysis.



Column {data-width=450}
-----------------------------------------------------------------------
 
### Introduction  {data-height=500}

<div style='margin:15px; font-size:17px;'>
Judging by the number of articles tagged with "data science" published on Medium.com since 2009, it is not an over-statement to say that the data science community there has exploded since. This makes it an interesting resource for investigating how the interests and characteristics of data scientists may have evolved with time.

One quick, but simplistic, approach to this is to measure which word pairs (bigrams) appear most frequently in the titles of articles published in each year, the result of which can be explored here. Please use the slider and knob in the side bar to select the year and number of top results that you are interested in, which then can be viewed as a network graph or data table under the different tabs. 

In the network graph, each word appears as a node and the directionality of the arrow connecting them to each other indicates the order in which they appears in a bigram. Finally, the darkness of the arrow connecting each pair of words is proportional to the frequency of appearance for that bigram. For example, we see much darker arrows connecting "data", "science" or "machine", "learning".

</div>

### Number of articles tagged "data science" published between 2009 and 2019 (as of November 21st)
 
```{r, fig.align='center'}
year_list <- c('2009-2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019')

freq_list <- list()

i <- 1

for (year in year_list) {
  df <- read.csv(sprintf('https://github.com/nchelaru/medium_scrapy/raw/master/processed/y%s_clean_titles.csv', year))
  freq_list[[year]]<- dim(df)[1]
}

df <- do.call(rbind, Map(data.frame, Year=year_list, num_articles=freq_list))

rownames(df) <- c()

ggplot(df, aes(x=Year, y=num_articles, fill=num_articles, label=num_articles)) + 
  geom_bar(stat = "identity") +
  geom_text(size = 4, position = position_stack(vjust = 1.1)) +
  scale_fill_gradient2(low='red', high='green') +
  labs(y = "Number of articles published", size=5) +
  theme_classic() +
  theme(legend.position="none") 
```
 

  
Column {data-width=550 .tabset .tabset-fade}
-----------------------------------------------------------------------

### Visualize network of top occurring bigrams 
 
```{r}
renderPlot({
  link <- sprintf("https://github.com/nchelaru/medium_scrapy/raw/master/processed/y%s_bigram_count_Nov21.csv", input$year)

  ## Import data
  bigram_counts <- read.csv(link) %>% select(-X) %>% arrange(desc(n))  
  
  ## Create graph
  bigram_graph <- head(bigram_counts, input$knob) %>%
    graph_from_data_frame()
  
  a <- grid::arrow(length = unit(0.15, "inches"), type = "closed")
          
  ggraph(bigram_graph, layout = "fr") +
    geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
                   arrow = a, end_cap = circle(.05, 'inches')) +
    geom_node_point(color = "lightblue", size = 5) +
    geom_node_text(aes(label = name), vjust = 1, hjust = 1, repel = TRUE, size=8) +
    theme_void() 
})

```

### Bigram frequency

```{r}
renderTable({
  link <- sprintf("https://github.com/nchelaru/medium_scrapy/raw/master/processed/y%s_bigram_count_Nov21.csv", input$year)

  bigram_counts <- read.csv(link) %>% select(-X) %>% arrange(desc(n))
  
  colnames(bigram_counts) <- c('Word 1', 'Word 2', 'Frequency')

  head(bigram_counts, input$knob)
  })
```


### General workflow

First, frequency of adjacent word pairs (bigrams) in article titles are counted for each year:

```Python
import collections
import nltk
import inflection as inf
import spacy
from spacy_langdetect import LanguageDetector

nlp = spacy.load('en_core_web_sm')

nlp.add_pipe(LanguageDetector(), 
             name="language_detector", 
             last=True)

counts = collections.Counter()

for sent in final_df["names"]:
  if type(sent) == str:
    doc = nlp(sent)
    
    word_list = []
    
    for token in doc:
      word_list.append(token.text.lower())
      
    counts.update(nltk.bigrams(word_list))
```

Then, the [workflow](https://www.tidytextmining.com/ngrams.html#counting-and-correlating-pairs-of-words-with-the-widyr-package) presented in the excellent reference *[Text Mining with R](https://www.tidytextmining.com/)* is used to visualize the most common bigrams and their relationships: 

```R
library(igraph)
library(ggraph)

bigram_graph <- bigram_counts %>% 
                    graph_from_data_frame()

a <- grid::arrow(type = "closed")

ggraph(bigram_graph, layout = "fr") + 
    geom_edge_link(aes(edge_alpha = n), show.legend = FALSE, 
                   arrow = a, end_cap = circle(0.07, "inches")) + 
    geom_node_point(color = "lightblue", size = 5) + 
    geom_node_text(aes(label = name), vjust = 1, 
                   hjust = 1, repel = TRUE) + 
    theme_void()
```

Topic trends over the years {.storyboard}
=========================================

Column {.sidebar}
-----------------------------------------------------------------------
<div style='margin:10px 5px 5px 5px;'>
Here, I manually selected a list of word pairs of interest and tracked the percentage of article titles (as indicated by both the size and colour of each circle) that contain them across the years. For ease of browsing, they are loosely grouped into six categories.

I intentionally left variations of the same word pair distinct, such as "data scientist" and "data scientist", in order to leave the data as close to its original form as possible.

This is by no means a rigorous study, only for personal interest. <i class="far fa-smile-wink"></i>
</div>


### General topics  

```{r, fig.width=9}
library(tidyr)
library(ggplot2)
library(ggpubr)
library(plotly)

df <- read.csv("./processed/top_bigrams_clean_Nov21.csv")

df <- unite(df, bigram, c(word1, word2), sep=" ", remove=FALSE)

df <- df[df$Category == 'General', ] %>% arrange(bigram)

x <- within(df, rm(word1, word2, Category))

rownames(x) <- x$bigram

x$bigram <- NULL

colnames(x) <- year_list

ggballoonplot(x, fill = 'value', size='value') +
  labs(x = "Year") +
  theme(axis.text.x = element_text(angle = 0, vjust=1, hjust=0.5),
        axis.title.x = element_text(size=12)) + 
   labs(fill="% of all word pairs in titles", size="% of all word pairs in titles")

```
 

### Tools and methods 

```{r, fig.width=9}
library(tidyr)
library(ggplot2)
library(ggpubr)
library(plotly)

df <- read.csv("./processed/top_bigrams_clean_Nov21.csv")

df <- unite(df, bigram, c(word1, word2), sep=" ", remove=FALSE)

df <- df[df$Category == 'Technology', ] %>% arrange(bigram)

x <- within(df, rm(word1, word2, Category))

rownames(x) <- x$bigram

x$bigram <- NULL

colnames(x) <- year_list

ggballoonplot(x, fill = 'value', size='value') +
  labs(x = "Year") +
  theme(axis.text.x = element_text(angle = 0, vjust=1, hjust=0.5),
        axis.title.x = element_text(size=12)) + 
   labs(fill="% of all word pairs in titles", size="% of all word pairs in titles")

```



### Programming languages  {data-commentary-width=400}

```{r, fig.width=9}
library(tidyr)
library(ggplot2)
library(ggpubr)
library(plotly)

df <- read.csv("./processed/top_bigrams_clean_Nov21.csv")

df <- unite(df, bigram, c(word1, word2), sep=" ", remove=FALSE)

df <- df[df$Category == 'Language', ] %>% arrange(bigram)
 
x <- within(df, rm(word1, word2, Category))

rownames(x) <- x$bigram

x$bigram <- NULL

colnames(x) <- year_list

ggballoonplot(x, fill = 'value', size='value') +
  labs(x = "Year") +
  theme(axis.text.x = element_text(angle = 0, vjust=1, hjust=0.5),
        axis.title.x = element_text(size=12)) + 
   labs(fill="% of all word pairs in titles", size="% of all word pairs in titles")
```


### Applications of data science {data-commentary-width=400}


```{r, fig.width=9}
library(tidyr)
library(ggplot2)
library(ggpubr)
library(plotly)

df <- read.csv("./processed/top_bigrams_clean_Nov21.csv")

df <- unite(df, bigram, c(word1, word2), sep=" ", remove=FALSE)

df <- df[df$Category == 'Application', ] %>% arrange(bigram)

x <- within(df, rm(word1, word2, Category))

rownames(x) <- x$bigram

x$bigram <- NULL

colnames(x) <- year_list

ggballoonplot(x, fill = 'value', size='value') +
  labs(x = "Year") +
  theme(axis.text.x = element_text(angle = 0, vjust=1, hjust=0.5),
        axis.title.x = element_text(size=12)) + 
   labs(fill="% of all word pairs in titles", size="% of all word pairs in titles")
```


### Learning data science {data-commentary-width=400}

```{r, fig.width=9}
library(tidyr)
library(ggplot2)
library(ggpubr)
library(plotly)

df <- read.csv("./processed/top_bigrams_clean_Nov21.csv")

df <- unite(df, bigram, c(word1, word2), sep=" ", remove=FALSE)

df <- df[df$Category == 'Learning', ] %>% arrange(bigram)

x <- within(df, rm(word1, word2, Category))

rownames(x) <- x$bigram

x$bigram <- NULL

colnames(x) <- year_list

ggballoonplot(x, fill = 'value', size='value') +
  labs(x = "Year") +
  theme(axis.text.x = element_text(angle = 0, vjust=1, hjust=0.5),
        axis.title.x = element_text(size=12)) + 
   labs(fill="% of all word pairs in titles", size="% of all word pairs in titles")
```



### Others {data-commentary-width=400}

```{r, fig.width=9}
library(tidyr)
library(ggplot2)
library(ggpubr)
library(plotly)

df <- read.csv("./processed/top_bigrams_clean_Nov21.csv")

df <- unite(df, bigram, c(word1, word2), sep=" ", remove=FALSE)

df <- df[df$Category == 'Others', ] %>% arrange(bigram)

x <- within(df, rm(word1, word2, Category))

rownames(x) <- x$bigram

x$bigram <- NULL

colnames(x) <- year_list

ggballoonplot(x, fill = 'value', size='value') +
  labs(x = "Year") +
  theme(axis.text.x = element_text(angle = 0, vjust=1, hjust=0.5),
        axis.title.x = element_text(size=12)) + 
   labs(fill="% of all word pairs in titles", size="% of all word pairs in titles")
```



Session info
=========================================
```{r}
sessionInfo()
```

